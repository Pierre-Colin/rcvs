\documentclass{report}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{hyperref}
\usepackage{mathrsfs}
\usepackage{listings}
\usepackage{tikz}

% Formatting help:
% https://www.scribendi.com/advice/format_a_scientific_paper.en.html

% Theorems
\theoremstyle{definition}
\newtheorem{ax}{Axiom}
\newtheorem{defn}{Definition}

\theoremstyle{plain}
\newtheorem{thm}{Theorem}

% Nice tables
\renewcommand{\arraystretch}{1.3}

% Rust listings
\lstdefinelanguage{Rust}{
	morekeywords={enum,use,extern,crate,impl,fn,match,if,else,for,while,
	              loop,pub,struct},
	classoffset=1,
	morekeywords={self,Some,None},
	keywordstyle=\color{red},
	classoffset=2,
	morekeywords={u64,Option},
	keywordstyle=\color{green!50!black},
	classoffset=0,
	sensitive=true,
	morecomment=[l]{//},
	morecomment=[l][\color{magenta}]{\#},
	morecomment=[s]{/*}{*/},
	morestring=[b]",
}

\lstset{
	language=Rust,
	backgroundcolor=\color{gray!25},
	basicstyle=\tt\tiny,
	captionpos=b,
	commentstyle=\color{blue},
	frame=single,
	keywordstyle=\color{orange},
	numbers=left,
	numbersep=5pt,
	numberstyle=\tiny\color{brown},
	rulecolor=\color{gray},
	stepnumber=5,
	stringstyle=\color{red},
	tabsize=4,
}

\title{A Concurrent Implementation of the Randomized Condorcet Voting System}
\author{Pierre Colin}
\date{}

\begin{document}
\maketitle

\begin{abstract}
TODO
\end{abstract}

\chapter{Democracy and election systems}
TODO

\section{Formalization of an election}
In a general election, the term \emph{alternative} is preferred to candidate as
the latter only applies well to human alternatives. The set of alternatives
will be noted $V$ because of an analogy with graph theory which will be made
clear in the next chapter.

\subsection{Naive ballots}
There are lots of ways to formalize ballots in an election. The one used here
relies on duels: a ballot will be a binary relation on $V$. In practice, an
elector would be given a grid where rows and columns are alternatives, and for
all squares, they would have to indicate which alternative they prefer. Of
course, the diagonal of the grid would have to be full of ties, and it would
have to be antisymmetric in the sense that a win of $x$ over $y$ in one square
needs to be reported as a loss of $y$ over $x$ in its symmetric square. As a
result, only a little below half of the grid needs to be filled, but this still
yields a ballot complexity of
$n\,\left(n\,-\,1\right) \,/\, 2\;
	=\; \underset{n\;\to\;\infty}\Theta\left(n^2\right)$
where $n\;=\;\left|V\right|$, and it would leave room for cyclical preferences.

The problem with cyclical preferences is that they open the doors to easy
scams. Consider the following: a person buys vanilla ice cream for \$1.00. The
ice cream man offers a one-cent switch of vanilla for chocolate, which the
customer accepts. The ice cream man then offers a one-cent switch of chocolate
for caramel, which the customer accepts. The ice cream man then offers a
one-cent switch of caramel for vanilla, which the customer accepts. The
customer has now paid \$1.03 for the same ice cream and may accept further
one-cent switches in the same fashion in such a way they may pay an unbounded
amount for an ice cream that is supposed to cost \$1.00.

\subsection{Strictly-preordered ballots}
To avoid cyclical preferences, the simple solution is to instead model ballots
as strict preorders over $V$. An elector has to give ranks to alternatives. An
alternative may be unranked, in which case it won't be compared to any other
alternative. The easy way to construct a strict preorder consists of giving all
ranked alternatives a range of ranks in $\mathbf N$. If we denote the unranked
property by $\varnothing$, this means constructing a function
$f:\;V\;\longmapsto\;\mathbf N^2\,\cup\,\left\{\varnothing\right\}$ such that
for all $v\;\in\;V$:
\begin{itemize}
\item if $v$ is unranked, then $f\left(v\right)\;=\;\varnothing$;
\item if $v$ is ranked, there exists $\left(a,\;b\right)\;\in\;\mathbf N^2$ such
      that $a\;\leqslant\;b$ and $f\left(v\right)\;=\;\left(a,\;b\right)$.
\end{itemize}
The alternatives can then be compared in the following way: for all
$\left(x,\;y\right)\;\in\;V^2$,
\begin{itemize}
\item if $f\left(x\right)\;=\;\varnothing$ or $f\left(y\right)\;=\;\varnothing$,
      then $x$ and $y$ are incomparable;
\item if $f\left(x\right)\;=\;\left(a_x,\;b_x\right)$ and
      $f\left(y\right)\;=\;\left(a_y,\;b_y\right)$, then $x\;<\;y$ if and only
      if $b_x\;<\;a_y$.
\end{itemize}
\begin{thm}
	The binary relation $<$ is a strict preorder over $V$.
\end{thm}
\begin{proof}
	Prove $<$ is irreflexive and transitive.
	\begin{description}
	\item[Irreflexivity:]
	Let $v\;\in\;V$. If $f\left(v\right)\;=\;\varnothing$, then $v$ is
	incomparable to itself. If $f\left(v\right)\;=\;\left(a,\;b\right)$
	with $a\;\leqslant\;b$, then we don't have $b\;<\;a$ hence we don't
	have $v\;<\;v$. In all cases, $v$ is incomparable to itself. Therefore,
	$<$ is irreflexive.
	\item[Transitivity:]
	Let $\left(x,\;y,\;z\right)\;\in\;V^3$ such that $x\;<\;y$ and
	$y\;<\;z$. Since they are pairwise comparable, they are all ranked.
	Destructure $f\left(x\right)\;=\;\left(a_x,\;b_x\right)$,
	$f\left(y\right)\;=\;\left(a_y,\;b_y\right)$ and
	$f\left(z\right)\;=\;\left(a_z,\;b_z\right)$. Combining properties on
	rank ranges and the definition of $<$ between alternatives,
	$b_x\;<\;a_y\;\leqslant\;b_y\;<\;a_z$ hence $b_x\;<\;a_z$ i.e.
	$x\;<\;z$. Therefore, $<$ is transitive.
	\end{description}
\end{proof}
By replacing all occurences of $<$ with $\leqslant$ and adding the constraint
$\forall v\;\in\;V,\;v\;\leqslant\;v$, it is possible to construct a preorder
over $V$. Preorders are a common way to model preferences, but insufficient for
modelling duels. A strict preorder property guarantees the absence of cycles,
and it is both easy to implement and yields a ballot of complexity
$n\;=\;\underset{n\;\to\;\infty}\Theta\left(n\right)$ where
$n\;=\;\left|V\right|$ which is much simpler than the naive ballot.

\section{Implementation}
Unlike what the theory suggests, the unranked property is not implemented in
the type \verb!Rank!. Instead, an unranked alternative is simply absent from
the ballot which is implemented as a \verb!HashMap<A, Rank>! where \verb!A!
denoes the generic type for alternatives. As the whole library makes use of
Rust's generics, \verb!A! requires some traits, namely \verb!std::cmp::Eq! and
\verb!std::hash::Hash!.

\subsection{Ranks}
First, implement ranks as a pair of 64-bit unsigned integers, and derive the
\verb!Debug! trait for testing purposes.
\begin{lstlisting}
#[derive(Debug)]
pub struct Rank(u64, u64);
\end{lstlisting}
However, not all pairs of 64-bit integers \verb!(a, b)! is a valid rank as the
constraint \verb!a <= b! is required. Because of that, a method \verb!new! is
needed for the type \verb!Rank! to make sure the rank given is valid.
\begin{lstlisting}
impl Rank {
    pub fn new(a: u64, b: u64) -> Option<Rank> {
        if a <= b {
            Some(Rank(a, b))
        } else {
            None
        }
    }
}
\end{lstlisting}

The trait \verb!fmt::Display! is implemented to print ranks in a pretty way.
The trait \verb!cmp::PartialEq! is implemented so that ranks never equal one
another. The trait \verb!cmp::PartialOrd! is implemented to reflect the strict
preorder that was defined in the previous section. This is done with the
following code:
\begin{lstlisting}
impl cmp::PartialOrd for Rank {
    fn partial_cmp(&self, other: &Rank) -> Option<cmp::Ordering> {
            match (self, other) {
                (&Rank(_, b), &Rank(a, _)) if b < a
                    => Some(cmp::Ordering::Less),
                (&Rank(a, _), &Rank(_, b)) if b < a
                    => Some(cmp::Ordering::Greater),
                _ => None,
            }
    }
}
\end{lstlisting}

\subsection{Ballots}
In order to be easily accessible by the client, ballots are implemented in the
root file \verb!lib.rs!. They are essentially a wrapped \verb!HashMap<A, Rank>!
with some convenient methods.
\begin{lstlisting}
pub struct Ballot<A: Hash> {
    m: HashMap<A, ballot::Rank>
}

impl <A: Hash + Eq> Ballot<A> {
    pub fn new() -> Ballot<A> {
        Ballot::<A>{ m: HashMap::<A, ballot::Rank>::new() }
    }

    pub fn insert(&mut self, x: A, a: u64, b: u64) -> bool {
        let or = ballot::Rank::new(a, b);
        match or {
            Some(r) => { self.m.insert(x, r); true },
            None => false,
        }
    }

    pub fn remove(&mut self, x: &A) -> bool {
        self.m.remove(x) != None
    }

    pub fn iter(&self) -> hash_map::Iter<A, ballot::Rank> {
        self.m.iter()
    }
}
\end{lstlisting}

The \verb!insert! method differs from the one provided by \verb!HashMap! in
that its return value indicates not the old value stored, but whether or not
the rank created is a valid one.

\chapter{The Condorcet Voting System}
The first main idea by Nicolas de Condorcet (1743--1794) is now known as the
Condorcet criterion.
\begin{ax}[Condorcet]
	If an alternative wins in one-versus-one duels against all others in an
	election, then it should be elected.
\end{ax}
Such an alternative is called a \emph{Condorcet winner}. This chapter explores
the Condorcet Voting System which is centered around this criterion.

\section{Definitions}
One-versus-one duels are typically visualized using graph theory.
\begin{defn}
	Let $V$ be the set of alternatives in the election. The \emph{duel
	graph} of the election is the oriented graph $\left(V,\;A\right)$ such
	that for all $\left(x,\;y\right)\;\in\;V^2$, the arrow
	$\overrightarrow{x\,y}$ is in $A$ if and only if more electors prefer $x$
	over $y$ than the opposite. Since it makes no sense to say that an
	alternative beats itself, duel graphs are trivially simple directed
	graphs.
\end{defn}
It may be useful to recall some theorems of graph theory which act as
interesting properties of duel graphs. Table \ref{tbl:duel_graph_vocab} shows
the correspondence between graph theory vocabulary and election system
vocabulary. Some of these correspondances are definitions; others are trivial
properties.
\begin{table}
	\centering
	\begin{tabular}{lr}
		\hline
		Graph theory & Election system \\
		\hline
		Vertice & Alternative \\
		$\overrightarrow{x\,y}\;\in\;A$ & $x$ beats $y$ \\
		$G$ is a tournament & There is no tie \\
		Source & Condorcet winner \\
		Sink & Condorcet loser \\
		\hline
	\end{tabular}
	\caption{Vocabulary of duel graphs}
	\label{tbl:duel_graph_vocab}
\end{table}
The duel graph of an election being a tournament is more likely as the number
of voters increases. Figure \ref{fig:duel_one_winner} shows a duel graph with a
unique Condorcet winner.
\begin{figure}
	\centering
	\begin{tikzpicture}[->, thick, node distance=3cm]
		\node[color=red] (A) {A};
		\node (B) [below left of=A] {B};
		\node (C) [below right of=A] {C};
		\path (A) edge (B)
		          edge (C)
		      (B) edge (C);
	\end{tikzpicture}
	\caption{A duel graph with \textcolor{red}{A} being a Condorcet winner}
	\label{fig:duel_one_winner}
\end{figure}

\begin{thm}
	A tournament has at most one source.
	\label{thm:tournament_sink}
\end{thm}
\begin{proof}
	Let $G\;=\;\left(V,\;A\right)$ be a tournament. Suppose by contradiction
	that it has two sources $x$ and $y$. Since $G$ is a tournament, exactly
	one of the arrows $\overrightarrow{x\,y}$ and $\overrightarrow{y\,x}$ is
	in $A$. Without loss of generality, assume the former. Then
	$\deg^-\left(y\right)\;>\;0$ i.e. $y$ is not a source, yielding a
	contradiction.
\end{proof}
Using all the notions presented in this section, the Condorcet method appears
to be simple: have electors express pairwise comparisons between alternatives,
build the duel graph and elect the alternative which corresponds to a sink in
the duel graph.

\section{The Condorcet paradox}
Unfortunately, there are situations in which the naive method alluded to at the
end of the previous section cannot be used. It is possible, albeit rare in
official elections, that there are zero or more than one Condorcet winners.
Figures \ref{fig:duel_no_winner} and \ref{fig:duel_two_winners} show these
situations. Note that the duel graph on figure \ref{fig:duel_two_winners} does
not contradict theorem \ref{thm:tournament_sink} because the graph is not a
tournament. The situation illustrated on figure \ref{fig:duel_no_winner} is
known as the \emph{Condorcet paradox}: even if the electors' individual
preferences are acyclical, the duel graph may be cyclical, meaning assuming
otherwise would be a fallacy of composition.
\begin{figure}
	\centering
	\begin{tikzpicture}[->, thick, node distance=3cm]
		\node (A) {A};
		\node (B) [below left of=A] {B};
		\node (C) [below right of=A] {C};
		\path (A) edge[bend right] (B)
		      (B) edge[bend right] (C)
		      (C) edge[bend right] (A);
	\end{tikzpicture}
	\caption{A duel graph with no Condorcet winner}
	\label{fig:duel_no_winner}
\end{figure}
\begin{figure}
	\centering
	\begin{tikzpicture}[->, thick, node distance=3cm]
		\node[color=red] (A) {A};
		\node (B) [below left of=A] {B};
		\node (C) [below right of=A] {C};
		\node[color=red] (D) [below right of=B] {D};
		\path (A) edge (B)
		          edge (C)
		      (B) edge (C)
		      (D) edge (B)
		          edge (C);
	\end{tikzpicture}
	\caption{A duel graph with \textcolor{red}{A} and \textcolor{red}{D}
	         both being Condorcet winners}
	\label{fig:duel_two_winners}
\end{figure}

In these situations, an alternative method needs to be used to fill the gaps
of the Condorcet method. Several methods exist, and the one used in this
project is fairly new. However, no matter what alternative method is used, the
naive Condorcet Voting System needs to be implemented since it is an inherent
part of all of the existing alternative methods.

\section{Implementation}
TODO

\chapter{Nondeterministic winner}
Thanks to game theory, new tools allowed to find solutions to the case where no
deterministic winner can be chosen, namely mixed strategies and the minimax
theorem. The main idea is that the winner is chosen randomly according to a
probability distribution which maximizes the average elector's utility
\footnote{the game theory term for happiness}.

\section{Rock-paper-scissors}
The first observation to be made is that duel graphs are isomorphic to the
rules of the generalized rock-paper-scissors game, where vertices correspond to
decisions and arrows model comparisons between decisions. Figure
\ref{fig:rock_paper_scissors} is copied from \ref{fig:duel_no_winner} with
renamed vertices to show exactly that. The game-theory properties of
rock-paper-scissors are:
\begin{description}
\item[2 players:] two players taking decisions;
\item[Non-cooperative:] players have no interest in helping each other;
\item[Symmetric:] the payoff of a strategy only depends on the opponent's
                  strategy;
\item[Zero sum:] the winner's utility gain equals the loser's utility loss;
\item[Simultaneous:] players make decisions without knowing the decisions made
                     by their opponent;
\item[Finite:] only three decisions possible;
\item[2 outcomes:] draw or win-loss.
\end{description}
\begin{figure}
	\centering
	\begin{tikzpicture}[->, thick, node distance=3cm]
		\node (A) {Rock};
		\node (B) [below left of=A] {Scissors};
		\node (C) [below right of=A] {Paper};
		\path (A) edge[bend right] (B)
		      (B) edge[bend right] (C)
		      (C) edge[bend right] (A);
	\end{tikzpicture}
	\caption{The rock-paper-scissors duel graph}
	\label{fig:rock_paper_scissors}
\end{figure}
Duel graphs may thus be seen as rock-paper-scissors-like games, and the goal is
to find an optimal strategy for this game. In the case of rock-paper-scissors,
there exist strategies based on psychology, but these work only because of
human cognitive biases. They should not be used in this context. One may argue
that no particular strategy can be derived for a simultaneous game, but this
is actually false as soon as players allow themselves to play randomly.

\section{Mixed strategies}
When playing rock-paper-scissors, it turns out that the best strategy is to
play randomly. In front of such a strategy, no counter-strategy can be devised,
and the expected win frequency is always $33\,\%$.

\begin{defn}
	Consider a finite, symmetric, simultaneous game. A \emph{mixed
	strategy} is a strategy in which the player randomly picks a decision
	according to a probability distribution.

	As both players can choose between $n\;=\;\left|V\right|$ decisions,
	such strategies are modeled as random variables over $V$.
\end{defn}

For convenience, define $I\;=\;\left\{1,\;\ldots,\;n\right\}$ and let
$\begin{array}[t]{cccl}v:&I&\longrightarrow&V \\
&n&\longmapsto&v\left(n\right)\end{array}$ be a bijection between $I$ and $V$.

\subsection{Comparison}
Let $X$ and $Y$ be two mixed strategies over $V$. Intuitively, $X$ beats $Y$ if
and only if
\begin{equation}
	\mathbf P\left(\overrightarrow{X\,Y}\;\in\;A\right)\;
	\geqslant\;\mathbf P\left(\overrightarrow{Y\,X}\;\in\;A\right).
	\label{eqn:compare_distributions}
\end{equation}

Some playing around may cast light on another formalism for mixed strategies.
Denoting the duel graph as $G\;=\;\left(V,\;A\right)$, Let \[
\begin{array}[t]{cccl}
s:&V&\longrightarrow&\mathscr P\left(V\right) \\
&x&\longmapsto&\left\{y\;\in\;V\mid\overrightarrow{x\,y}\;\in\;A\right\}
\end{array}
\] be the function giving the successors of a vertice in $G$. Noting that the
game is simultaneous, $X$ and $Y$ are independent and equation
\ref{eqn:compare_distributions} becomes \[
	\sum_{x\;\in\;V}\mathbf P\left(X\;=\;x\right)\,
	\sum_{y\;\in\;s\left(x\right)}\mathbf P\left(Y\;=\;y\right)
	\;\geqslant\;
	\sum_{y\;\in\;V}\mathbf P\left(Y\;=\;y\right)\,
	\sum_{x\;\in\;s\left(y\right)}\mathbf P\left(X\;=\;x\right).
\] which can be rearranged as
\begin{equation}
	\sum_{x\;\in\;V}\sum_{y\;\in\;s\left(x\right)}\left(
	\mathbf P\left(X\;=\;x\right)\,\mathbf P\left(Y\;=\;y\right)
	\,-\,
	\mathbf P\left(Y\;=\;x\right)\,\mathbf P\left(X\;=\;y\right)\right)
	\;\geqslant\;0.
	\label{eqn:rearranged_comparison}
\end{equation}

\subsection{Mixed vectors}
Let $M\;=\;\left(m_{i,\;j}\right)_{\left(i,\;j\right)\;\in\;I^2}
\;\in\;\mathscr M_n\left(\mathbf R\right)$ be the matrix defined by \[
	\forall\left(i,\;j\right)\;\in\;I^2,\;m_{i,\;j}\;=\;
	\begin{cases}
		1\qquad\text{if }
			\overrightarrow{v\left(i\right)\,v\left(j\right)}
				\;\in\;A \\
		-1\qquad\text{if }
			\overrightarrow{v\left(j\right)\,v\left(i\right)}
				\;\in\;A \\
		0\qquad\text{otherwise}
	\end{cases}.
\]

\begin{thm}
	The matrix $M$ is skew-symmetric.
\end{thm}
\begin{proof}
	Let $\left(i,\;j\right)\;\in\;I^2$. If $i\;=\;j$, then
	$\overrightarrow{v\left(i\right)\,v\left(j\right)}\;\notin\;A$ thus
	$m_{i,\;j}\;=\;0$. Assume $i\;\neq\;j$. Since $G$ is oriented, exactly
	one of the following is true:
	\begin{enumerate}
	\item $\overrightarrow{v\left(i\right)\,v\left(j\right)}\;\notin\;A$
	      and
	      $\overrightarrow{v\left(j\right)\,v\left(i\right)}\;\notin\;A$,
	      then $m_{i,\;j}\;=\;0\;=\;-m_{j,\;i}$.
	\item $\overrightarrow{v\left(i\right)\,v\left(j\right)}\;\in\;A$
	      and
	      $\overrightarrow{v\left(j\right)\,v\left(i\right)}\;\notin\;A$,
	      then $m_{i,\;j}\;=\;1\;=\;-\left(-1\right)\;=\;-m_{j,\;i}$.
	\item $\overrightarrow{v\left(i\right)\,v\left(j\right)}\;\notin\;A$
	      and
	      $\overrightarrow{v\left(j\right)\,v\left(i\right)}\;\in\;A$,
	      then $m_{i,\;j}\;=\;-1\;=\;-m_{j,\;i}$.
	\end{enumerate}
	In all cases, $m_{i,\;j}\;=\;-m_{j,\;i}$, thus $M$ is skew-symmetric.
\end{proof}

\begin{defn}
	Let $X$ be a mixed strategy over $V$. The \emph{mixed vector} assigned
	to $X$ is \[
		\left(\mathbf P\left(X\;
				=\;v\left(i\right)\right)\right)
			_{i\;\in\;I}
		\;\in\;\mathscr M_{n,\;1}\left(\mathbf R\right).
	\]
\end{defn}

Taking equation \ref{eqn:rearranged_comparison} with
$P\;=\;\left(p_i\right)_{i\;\in\;I}$ and $Q\;=\;\left(q_i\right)_{i\;\in\;I}$
being the mixed vectors assigned to $X$ and $Y$ respectively, \[
	\sum_{i\;\in\;I}
	\sum_{\substack{j\;\in\;I \\ m_{i,\;j}\;=\;1}}
	\left(p_i\,q_j\,-\,q_i\,p_j\right)
	\;\geqslant\;0.
\] Using $M$'s skew-symmetry,
\begin{align*}
	\sum_{i\;\in\;I}
	\sum_{\substack{j\;\in\;I \\ m_{i,\;j}\;=\;1}}
	\left(p_i\,q_j\,-\,q_i\,p_j\right)
	\;&=\;
	\sum_{\substack{\left(i,\;j\right)\;\in\;I^2 \\ m_{i,\;j}\;=\;1}}
	\left(p_i\,q_j\,-\,q_i\,p_j\right) \\
	&=\;
	\sum_{\substack{\left(i,\;j\right)\;\in\;I^2 \\ m_{i,\;j}\;=\;1}}
	p_i\,q_j
	\,-\,\sum_{\substack{\left(i,\;j\right)\;\in\;I^2 \\ m_{i,\;j}\;=\;1}}
	q_i\,p_j \\
	&=\;
	\sum_{\substack{\left(i,\;j\right)\;\in\;I^2 \\ m_{i,\;j}\;=\;1}}
	p_i\,1\,q_j
	\,+\,\sum_{\substack{\left(i,\;j\right)\;\in\;I^2 \\ m_{j,\;i}\;=\;-1}}
	p_j\,\left(-1\right)\,q_i \\
	&=\;
	\sum_{\substack{\left(i,\;j\right)\;\in\;I^2 \\ m_{i,\;j}\;=\;1}}
	p_i\,1\,q_j
	\,+\,\sum_{\substack{\left(i,\;j\right)\;\in\;I^2 \\ m_{i,\;j}\;=\;-1}}
	p_i\,\left(-1\right)\,q_j.
\end{align*}
Since $\forall\left(i,\;j\right)\;\in\;I^2,\;
m_{i,\;j}\;\in\;\left\{-1,\;0,\;1\right\}$, noting $M_i$ the $i$th row of $M$,
the two sums can be merged into
\begin{align*}
	\sum_{\left(i,\;j\right)\;\in\;I^2}p_i\,m_{i,\;j}\,q_j
	\;&=\;\sum_{i\;\in\;I}\sum_{j\;\in\;I}p_i\,m_{i,\;j}\,q_j \\
	&=\;\sum_{i\;\in\;I}p_i\,\sum_{j\;\in\;I}m_{i,\;j}\,q_j \\
	&=\;\sum_{i\;\in\;I}p_i\,\left(M_i\,Q\right) \\
	&=\;\sum_{i\;\in\;I}\left(p_i\,M_i\right)\,Q \\
	&=\;\left(\sum_{i\;\in\;I}p_i\,M_i\right)\,Q \\
	&=\;\left(P^\top\,M\right)\,Q \\
	&=\;P^\top\,M\,Q \\
\end{align*}

From this observation, a preorder on mixed vectors can be defined.
\begin{defn}
	\label{defn:mixed_vector}
	Let $\mathbf P$ be the set of vectors $\left(p_i\right)_{i\;\in\;I}
	\;\in\;\mathscr M_{n,\;1}\left(\mathbf R\right)$ such that
	$\forall i\;\in\;I,\;p_i\;\geqslant\;0$ and $\sum_{i\;\in\;I}p_i\;1$.
	Introduce a binary relation $\leqslant$ over $\mathbf P$ such that for
	all $\left(P,\;Q\right)\;\in\;\mathbf P^2$,
	\[P\;\leqslant\;Q\quad\Leftrightarrow\quad P^\top\,M\,Q\;\leqslant\;0.\]
\end{defn}

By the manipulations done above, the notion of mixed vector is isomorphic to
that of mixed strategies, and the binary relation between mixed vectors is
equivalent to mixed strategies beating each other.

\begin{thm}
	The binary relation $\leqslant$ is reflexive and total.
\end{thm}
\begin{proof}
	Prove that $\leqslant$ is reflexive and transitive.
	\begin{description}
	\item[Reflexivity:] Let $P\;\in\;\mathbf P$. Since $P$ only has
		nonnegative coordinates,
		\begin{align*}
		P^\top\,M\,P
		\;&=\;\sum_{\left(i,\;j\right)\;\in\;I^2}p_i\,m_{i,\;j}\,p_j \\
		&=\;\sum_{\substack{\left(i,\;j\right)\;\in\;I^2 \\
		                    m_{i,\;j}\;=\;1}}
			p_i\,p_j
		\,-\,\sum_{\substack{\left(i,\;j\right)\;\in\;I^2 \\
		                     m_{i,\;j}\;=\;-1}}
			p_i\,p_j \\
		&=\;\sum_{\substack{\left(i,\;j\right)\;\in\;I^2 \\
		                    m_{i,\;j}\;=\;1}}
			p_i\,p_j
		\,-\,\sum_{\substack{\left(i,\;j\right)\;\in\;I^2 \\
		                     m_{j,\;i}\;=\;1}}
			p_j\,p_i \\
		&=\;0\;\leqslant\;0.
		\end{align*}
		Therefore $\leqslant$ is reflexive.
	\item[Totality:] Let $\left(P,\;Q\right)\;\in\;\mathbf P^2$. Suppose
		$P\;\leqslant\;Q$ is false. Then $P^\top\,M\,Q\;>\;0$. But
		$P^\top\,M\,Q\;=\;\left(Q^\top\,M^\top\,P\right)^\top$, and
		since this quantity is a scalar and $M$ is skew-symmetric, it
		equals $-Q^\top\,M\,P\;>\;0$ i.e. $Q^\top\,M\,P\;<\;0$ then
		$Q\;\leqslant\;P$. Therefore, $\leqslant$ is total.
	\end{description}
\end{proof}

\subsection{Maximal strategies}
The goal is now to find an \emph{optimal} mixed strategy. The minimax approach
will be useful for that. The following calculations are taken from oscar6echo's
notebook\cite{oscar6echo}. Both the minimax and maximin strategies are covered
here, although they are extremely similar.

\subsubsection{Minimax strategy}
Suppose player B wants to choose a strategy $\mathbf p\;\in\;\mathbf P$ that will
maximize its payoff, i.e. minimize A's, no matter what mixed strategy player A
plays. Since mixed strategies are barycenters of pure strategies, $\mathbf p$'s
worst payoff will occur at some pure strategy. Noting $R_i$ the $i$th row of
$M$, A's expected payoff is then
\[v\;=\;\min_{\mathbf p\;\in\;\mathbf P}\,\max_{i\;\in\;I}\,R_i\,\mathbf p.\]
Since the maximum is equivalent to the least upper bound,
\[
	v\;=\;\min_{\mathbf p\;\in\;\mathbf P}\,
		\min_{\beta\;\in\;\mathbf R}\,\beta
		\qquad\text{subject to}\qquad
		\forall i\;\in\;I,\;R_i\,\mathbf p\;\leqslant\;\beta.
\]
Merging both minima,
\begin{equation}
	v\;=\;\min_{\substack{\mathbf p\;\in\;\mathbf P\\\beta\;\in\;\mathbf R}}\,\beta
		\qquad\text{subject to}\qquad
		\forall i\;\in\;I,\;R_i\,\mathbf p\;\leqslant\;\beta.
	\label{eqn:minimax_1}
\end{equation}
Two things can be done from here. First, for all $\left(i,\;j\right)\;\in\;I^2$,
define $a_{i,\;j}\;=\;m_{i,\;j}\,+\,2$ so that the matrix $A$ has only positive
coordinates. Then for all $i\;\in\;I$, noting $R'_i$ the $i$th column of $A$,
\begin{align*}
	R'_i\,\mathbf p\;&=\;\sum_{j\;\in\;I}a_{i,\;j}\,p_j \\
		&=\;\sum_{j\;\in\;I}\left(m_{i,\;j}\,+\,2\right)\,p_j \\
		&=\;\sum_{j\;\in\;I}\left(m_{i,\;j}\,p_j\,+\,2\,p_j\right) \\
		&=\;\sum_{j\;\in\;I}m_{i,\;j}\,p_j\,+\,2\,\sum_{j\;\in\;I}p_j \\
		&=\;\sum_{j\;\in\;I}m_{i,\;j}\,p_j\,+\,2 \\
		&=\;R_i\,\mathbf p\,+\,2.
\end{align*}
This guarantees switching from $M$ to $A$ will only shift $a$ by 2, but this
minimum will still occur at the same $\mathbf p$. Let $\beta'\;=\;\beta\,+\,2$.
Equation \ref{eqn:minimax_1} becomes
\begin{equation}
	v'\;=\;\min_{\substack{P\;\in\;\mathbf P\\\beta'\;\in\;\mathbf R}}\,\beta'
		\qquad\text{subject to}\qquad
		\forall i\;\in\;I,\;R'_i\,P\;\leqslant\;\beta'
	\label{eqn:minimax_2}
\end{equation}
where $v'\;=\;v\,+\,2$. The second thing to do is to define the following
partial order over $\mathscr M_{n,\;1}\left(\mathbf R\right)$:
\[
	\forall\left(\mathbf x,\;\mathbf y\right)
		\;\in\;\mathscr M_{n,\;1}\left(\mathbf R\right)^2,\;\left(
		\mathbf x\;\leqslant\;\mathbf y
		\qquad\Leftrightarrow\qquad
		\forall i\;\in\;I,\;x_i\;\leqslant\;y_i
	\right).
\]
This notation allows rewriting equation \ref{eqn:minimax_2} into problem
\ref{eqn:minimax_3}, defining the vectors
$\mathbf 1\;=\;\left(1\right)_{i\;\in\;I}$ and
$\mathbf 0\;=\;\left(0\right)_{i\;\in\;I}$.
\begin{equation}
	\begin{array}{lll}
		\text{Minimize} & & \beta' \\
		\text{subject to} & &
			A\,\mathbf p\;\leqslant\;\beta'\,\mathbf 1 \\
		\text{and} & & \mathbf p\;\geqslant\;\mathbf 0
	\end{array}
	\label{eqn:minimax_3}
\end{equation}
Since $\forall\left(i,\;j\right)\;\in\;I^2,\;a_{i,\;j}\;>\;0$, it follows that
$\forall i\;\in\;I,\;R'_i\,\mathbf p\;>\;0$ then $a'\;>\;0$. Define
$\mathbf x\;=\;\frac1{\beta'}\,\mathbf p$. Problem \ref{eqn:minimax_3} becomes
\[
	\begin{array}{lll}
		\text{Minimize} & & \beta' \\
		\text{subject to} & & A\,\mathbf x\;\leqslant\;\mathbf 1 \\
		\text{and} & & \mathbf x\;\geqslant\;\mathbf 0
	\end{array}
\]
Since $\mathbf 1^\top\,\mathbf x\;=\;\sum_{i\;\in\;I}x_i\;=\;\frac1{\beta'}$,
this is equivalent to problem \ref{eqn:lp_minimax}.
\begin{equation}
	\begin{array}{lll}
		\text{Maximize} & & \mathbf 1^\top\,\mathbf x \\
		\text{subject to} & & A\,\mathbf x\;\leqslant\;\,\mathbf 1 \\
		\text{and} & & \mathbf x\;\geqslant\;\mathbf 0
	\end{array}
	\label{eqn:lp_minimax}
\end{equation}
If $\mathbf x$ is known, $\mathbf x$ can be calculated with
$\mathbf p\;=\;\frac1{\left\|\mathbf x\right\|_1}\,\mathbf x$ where
$\left\|\cdot\right\|_1$ refers to the $L^1$-norm. Of course, this work is
useful only if $\mathbf x$ is computable, which is nontrivial.

\subsubsection{Maximin strategy}
For the maximin strategy, things are almost identical. Suppose player A wants
to choose a strategy $\mathbf p\;\in\;\mathbf P$ that will maximize its payoff
no matter what mixed strategy player B plays. Since mixed strategies are
barycenters of pure strategies, $\mathbf p$'s worst payoff occurs for some pure
strategy. Noting $C_i$ the $i$th column of $M$, A's expected payoff is then
\[
	v\;=\;\max_{\mathbf p\;\in\;\mathbf P}\,
		\min_{j\;\in\;I}\,\mathbf p^\top\,C_j.
\]
Since the minimum is equivalent to the greatest lower bound,
\[
	v\;=\;\max_{\mathbf p\;\in\;\mathbf P}\,
		\max_{\beta\;\in\;\mathbf R}\,\beta
		\qquad\text{subject to}\qquad
		\forall j\;\in\;I,\;\mathbf p^\top\,C_j\;\geqslant\;\beta.
\]
Merging both maxima gives equation \ref{eqn:maximin_1}.
\begin{equation}
	v\;=\;\max_{\substack{\mathbf p\;\in\;\mathbf P\\\beta\;\in\;\mathbf R}}\,\beta
		\qquad\text{subject to}\qquad
		\forall j\;\in\;I,\;\mathbf p^\top\,C_j\;\geqslant\;\beta.
	\label{eqn:maximin_1}
\end{equation}
Take the matrix $A$ as in the minimax strategy, and for $j\;\in\;I$, note $C'_j$
its $j$th column. Then, in a similar fashion,
$\mathbf p^\top\,C'_j\;=\;\mathbf p^\top\,C_j\,+\,2$ meaning that the maximum
will occur for the same $\mathbf p$ with $\beta'\;=\;\beta\,+\,2$. Taking the
same coordinatewise partial order over
$\mathscr M_{n,\;1}\left(\mathbf R\right)$, equation \ref{eqn:maximin_1} becomes
problem \ref{eqn:maximin_2}.
\begin{equation}
	\begin{array}{lll}
		\text{Maximize} & & \beta' \\
		\text{subject to} & &
			A^\top\,\mathbf p\;\geqslant\;\beta'\,\mathbf 1 \\
		\text{and} & & \mathbf p\;\geqslant\;\mathbf 0
	\end{array}
	\label{eqn:maximin_2}
\end{equation}
Note that this time, $\mathbf p^\top\,A$ was transposed into $A^\top\,\mathbf p$
to keep a column structure. It should be kept in mind that contrarily to $M$,
$A$ is not skew-symmetric.

Since $\forall\left(i,\;j\right)\;\in\;I^2,\;a_{i,\;j}\;>\;0$, it follows that
$\forall j\;\in\;I,\;\mathbf p^\top\,C'_j\;>\;0$ then $\beta'\;>\;0$. Define
$\mathbf x\;=\;\frac1{\beta'}\,\mathbf p$. Problem \ref{eqn:maximin_2} becomes
problem \ref{eqn:lp_maximin}.
\begin{equation}
	\begin{array}{lll}
		\text{Minimize} & & \mathbf 1^\top\,\mathbf x \\
		\text{subject to} & &
			A^\top\,\mathbf x\;\geqslant\;\,\mathbf 1 \\
		\text{and} & & \mathbf x\;\geqslant\;\mathbf 0
	\end{array}
	\label{eqn:lp_maximin}
\end{equation}
If $\mathbf x$ is known, $\mathbf p$ can be calculated with
$\mathbf p\;=\;\frac1{\left\|\mathbf x\right\|_1}\,\mathbf x$. Of course, this
work is useful only if $X$ is computable, which is nontrivial.

\section{Computation}
The previous work was not for nothing: problems
\ref{eqn:lp_minimax} and \ref{eqn:lp_maximin} are of
a specific class of problems called \emph{linear programs}. They can be brought
to canonical form as shown on figure \ref{fig:lp_standard}. These two programs
also turn out to be \emph{symmetric duals} of each others, but this property
will not be used here.
\begin{figure}[ht!]
	\centering
	\begin{tabular}{|lll|}
		\hline
		\multicolumn{3}{|c|}{Minimax} \\
		\hline
		Minimize & & $-\mathbf 1^\top\,\mathbf x$ \\
		subject to & & $A\,\mathbf x\;\leqslant\;\mathbf 1$ \\
		and & & $\mathbf x\;\geqslant\;\mathbf 0$ \\
		\hline
	\end{tabular}
	\begin{tabular}{|lll|}
		\hline
		\multicolumn{3}{|c|}{Maximin} \\
		\hline
		Minimize & & $\mathbf 1^\top\,\mathbf x$ \\
		subject to & & $-A^\top\,\mathbf x\;\leqslant\;-\mathbf 1$ \\
		and & & $\mathbf x\;\geqslant\;\mathbf 0$ \\
		\hline
	\end{tabular}
	\caption{Linear programs in standard form}
	\label{fig:lp_standard}
\end{figure}

Geometrically speaking, linear programming consists of minimizing a linear form
over a closed convex polytope whose all vertices have nonnegative coordinates.
The naive approach to it would be to use gradient descent. After all, the
gradient of a linear form is constant ($-\mathbf 1$ and $\mathbf 1$ in our
case). Unfortunately, one theorem makes this dream vanish.
\begin{thm}
	\label{thm:minimum_vertex}
	Let $\left(\mathbf V,\; +,\; \cdot\right)$ be a vector space of
	arbitrary dimension over $\mathbf R$, $u\;\in\;\mathbf V^*$ and $P$ a
	closed convex polytope in $\mathbf V$.

	The function $u\upharpoonright_P$ has a minimum value reached at one
	of $P$'s vertices.
\end{thm}
\begin{proof}
	Note $V$ the set of $P$'s vertices. Since $P$ is a convex polytope, it
	is the convex hull of $V$. The set $V$ being finite, let
	$m\;=\;\min_V\,u$. Then, for all $\mathbf x\;\in\;P$, there exists
	nonnegative coefficients $\left(\gamma_\mathbf v\right)_{\mathbf
	v\;\in\;V}$ such that
	\[
		\begin{cases}
			\sum_{\mathbf v\;\in\;V}\gamma_\mathbf v\;=\;1 \\
			\mathbf x\;=\;\sum_{\mathbf v\;\in\;V}
				\gamma_\mathbf v\,\mathbf v
		\end{cases}.
	\]
	Then,
	\begin{align*}
		u\left(\mathbf x\right)\;&=\;u\left(\sum_{\mathbf v\;\in\;V}
				\gamma_\mathbf v\,\mathbf v\right) \\
			&=\;\sum_{\mathbf v\;\in\;V}
				\gamma_\mathbf v\,u\left(\mathbf v\right) \\
			&\geqslant\;\sum_{\mathbf v\;\in\;V}\gamma_\mathbf v\,m \\
			&=\;m\,\sum_{\mathbf v\;\in\;V}\gamma_\mathbf v \\
			&=\;m.
	\end{align*}
\end{proof}
Beside the fact that theorem \ref{thm:minimum_vertex} has a very general scope
(it works even in infinite dimension and without an inner product), it shows
that the minimum point is not interior to the domain where gradient descent
usually works. Therefore, linear programming requires its very own toolbox.

The two most famous algorithms for linear programming are the \emph{simplex
algorithm} and the \emph{ellipsoid algorithm}. Although the latter has a better
worst-case time complexity, the linear programs solved here have moderate size.
The former method will therefore be used.

\subsection{The simplex algorithm}
Consider the following linear program. Ignore the "N" subscripts for now.
\begin{center}
	\begin{tabular}{|lll|}
		\hline
		Minimize & & $\mathbf {c_{\rm N}}^\top\,\mathbf x_{\rm N}$ \\
		subject to & & $A_{\rm N}\,\mathbf x_{\rm N}\;\leqslant\;\mathbf b$ \\
		and & & $\mathbf x_{\rm N}\;\geqslant\;\mathbf 0$ \\
		\hline
	\end{tabular}
\end{center}
The simplex algorithm requires transforming the problem by making the first
constraint an equality. The solution is to introduce \emph{slack variables}. A
constraint of the type $R_i\,\mathbf x\;\leqslant\;b_i$ is then turned into a
constraint of the form $R_i\,\mathbf x\,+\,s_i\;=\;b_i$. Usually, a slack
variable in a constraint of type $\geqslant$ is called a \emph{surplus
variable}, but they don't behave any different. Note $m\,\times\,n$ the shape
of $A_{\rm N}$. The most important thing to keep in mind is that $m$ is the
\emph{number of constraints} and $n$ is the \emph{number of variables}. The new
matrices are then defined in equation \ref{eqn:simplex_form}.
\begin{equation}
	\begin{array}{|lcl|}
		\hline
		A_{\rm B}\;=\;I_m & \longrightarrow &
			A\;=\;\left(\begin{array}{c|c}
				A_{\rm B} & A_{\rm N}
			\end{array}\right)\;\in\;
				\mathscr M_{m,\;m\,+\,n}
					\left(\mathbf R\right) \\
		\mathbf c_{\rm B}\;=\;\mathbf 0 & \longrightarrow &
			\mathbf c\;=\;\left(\begin{array}{c}
				\mathbf c_{\rm B} \\
				\hline
				\mathbf c_{\rm N}
			\end{array}\right)\;\in\;
				\mathscr M_{m\,+\,n,\;1}
					\left(\mathbf R\right) \\
		\mathbf x_{\rm B}\;\in\;\mathscr M_{m,\;1}\left(\mathbf R\right)
			& \longrightarrow &
			\mathbf x\;=\;\left(\begin{array}{c}
				\mathbf x_{\rm B} \\
				\hline
				\mathbf x_{\rm N}
			\end{array}\right)\;\in\;
				\mathscr M_{m\,+\,n,\;1}
					\left(\mathbf R\right) \\
		\hline
	\end{array}
	\label{eqn:simplex_form}
\end{equation}
The value of $\mathbf x_{\rm B}$ is unspecified for now because it is part of
what is to be computed. The problem then becomes
\begin{center}
	\begin{tabular}{|lll|}
		\hline
		Minimize & & $\mathbf c^\top\,\mathbf x$ \\
		subject to & & $A\,\mathbf x\;=\;\mathbf b$ \\
		and & & $\mathbf x\;\geqslant\;\mathbf 0$ \\
		\hline
	\end{tabular}
\end{center}
where $A$ is not necessarily square, meaning $A\,\mathbf x\;=\;\mathbf b$ has
potentially infinitely many solutions.

The set of $\mathbf x$ such that $A\,\mathbf x\;=\;\mathbf b$ and $\mathbf
x\;\geqslant\;\mathbf 0$ is called the \emph{feasible region}, and its elements
are \emph{feasible vectors}. A component $\mathbf x_{\rm B}$ of a feasible
vector is called a \emph{feasible basic vector} or feasible basis. All
subscripts "B" mean \emph{basic} while subscripts "N" mean \emph{nonbasic}. The
term \emph{objective function} refers to $\mathbf c$.

The idea is as follows: the vector $\mathbf x_{\rm B}$ will start at one of the
vertices of the convex polytope, and at each iteration, it will follow an edge
to the neighboring vertex which best reduces the objective function until no
neighboring vertex is better.

The details of the algorithm are described in \cite{num_rec}, but some
clarifications need to be made as the authors did not give all the details.

\subsubsection{Auxiliary objective function}
One question that is not addressed in \cite{num_rec} is what auxiliary
objective function $\mathbf c$ to choose in case solving
$A_{\rm B}\,\mathbf x_{\rm B}\;=\;\mathbf b$ did not give a feasible basic
vector. The solution is to use $\tilde{\mathbf c}$ defined as
\[
	\forall i\;\in\;\left\{1,\;\ldots,\;n\right\},\;\tilde{\mathbf c}_n
		\;=\;\begin{cases}
			1 & \text{if } x_i\;<\;0 \\
			0 & \text{otherwise}
		\end{cases}.
\]
This auxiliary objective function needs not be calculated again at each
iteration.

\subsubsection{Minimum ratio test}
In \cite{num_rec}, the minimum ratio test is done filtering the $x_i\,/\,w_i$s
to those with $w_i\;>\;0$, but this is for the main iterative phase. Nothing is
said for the feasible-basic-vector phase where both $\mathbf x_{\rm B}$ and
$\mathbf w$ behave very differently. This time, the correct filter is
$x_i\;<\;0$.

\subsubsection{Computation of the reduced costs}
The reduced costs are computed in \cite{num_rec} by solving
${A_{\rm B}}^\top\,\mathbf y\;=\;\mathbf c_{\rm B}$ and, for each
$k\;\in\;\left\{1,\;\ldots,\;n\right\}$, computing
$u_k\;=\;c_k\,-\,{\mathbf a_k}^\top\,\mathbf y$. However, it is possible to
compute all the $u_k$s at the same time in the form of a vector $\mathbf u$.
This is because $c_k$ are the coordinates of $\mathbf c_{\rm B}$ and
$\mathbf a_k$ are the columns of $A_{\rm B}$. An interesting observation is
that the columns of $A_{\rm B}$ are the rows of ${A_{\rm B}}^\top$, leading to
\[
	\mathbf u
		\;=\;\mathbf c_{\rm B}
			\,-\,\left({A_{\rm B}}^\top\right)^\top\,\mathbf y
		\;=\;\mathbf c_{\rm B}\,-\,A_{\rm B}\,\mathbf y.
\]
This allows to get all the $u_k$s in one formula if a matrix algebra library is
available.

\begin{thebibliography}{9}
\bibitem{oscar6echo}
	oscar6echo,
	\textit{Randomized Condorcet Voting System (RCVS)},
	Jupyter,
	\href{https://nbviewer.jupyter.org/github/oscar6echo/randomized-condorcet-voting-system/blob/master/Randomized-Condorcet-Voting-System.ipynb}{on-line}.

\bibitem{num_rec}
	William H. Press, Saul A. Teukolsky,
	William T. Vetterling, Brian P. Flannery,
	\textit{Numerical Recipes: The Art of Scientific Computing},
	third edition (2007),
	Cambridge University Press,
	\href{http://numerical.recipes/aboutNR3book.html}{ISBN-10: 0521880688}.
\end{thebibliography}
\end{document}
